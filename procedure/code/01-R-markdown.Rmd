---
title: "Gerrymandering in Alabama"
author: "Gus Howard"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs/report") })
---


# Study metadata

- `Title`: Voting Precincts 2020
- `Abstract`: Alabama voting data for 2020 elections by precinct.
- `Spatial Coverage`: Alabama
- `Spatial Resolution`: Voting precincts
- `Spatial Reference System`: EPSG 4269 NAD 1983 geographic coordinate system
- `Temporal Coverage`: precincts used for tabulating the 2020 census
- `Temporal Resolution`: annual election

- `Title`: Voting Districts 2020
- `Abstract`: Congressional Districts
- `Spatial Coverage`: Alabama
- `Spatial Resolution`: US Congressional Districts
- `Spatial Reference System`: EPSG 3857 WGS 1984 Web Mercator projection
- `Temporal Coverage`: Districts approved in 2023 for 2024
- `Temporal Resolution`: annual election

- `Title`: Block Groups 2020
- `Abstract`: Vector polygon geopackage layer of 2020 Census Block Groups and demographic data
- `Spatial Coverage`: Alabama
- `Spatial Resolution`: Census Block Groups
- `Spatial Reference System`: EPSG 4269 NAD 1983 geographic coordinate system
- `Temporal Coverage`: 2020 Census
- `Temporal Resolution`: 2020 Census


# Study design

This is an original study based on literature on gerrymandering metrics.

It is an exploratory study to evaluate the usefulness of a new gerrymandering metric based on
the convex hull of a congressional district and the representativeness inside the convex hull compared to the congressional district.

Enumerate specific **hypotheses** to be tested or **research questions** to be investigated here, and specify the type of method, statistical test or model to be used on the hypothesis or question.

# Materials and procedure

## Computational environment

I Plan on using package.... for...


```{r environment-setup, include = FALSE}
# record all the packages you are using here
# this includes any calls to library(), require(),
# and double colons such as here::i_am()
packages <- c("tidyverse", "here", "sf", "tmap", "tidycensus")

# force all conflicts to become errors
# if you load dplyr and use filter(), R has to guess whether you mean dplyr::filter() or stats::filter()
# the conflicted package forces you to be explicit about this
# disable at your own peril
# https://conflicted.r-lib.org/
require(conflicted)

# load and install required packages
# https://groundhogr.com/
if (!require(groundhog)) {
  install.packages("groundhog")
  require(groundhog)
}

if (!require(here)) {
  install.packages("here")
  require(here)
}

# this date will be used to determine the versions of R and your packages
# it is best practice to keep R and its packages up to date
groundhog.day <- "2025-02-01"

# this replaces any library() or require() calls
groundhog.library(packages, groundhog.day)
# you may need to install a correct version of R
# you may need to respond OK in the console to permit groundhog to install packages
# you may need to restart R and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# record the R processing environment
# alternatively, use devtools::session_info() for better results
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# save package citations
knitr::write_bib(c(packages, "base"), file = here("software.bib"))

# set up default knitr parameters
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(
  echo = FALSE, # Run code, show outputs (don't show code)
  fig.retina = 4,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)
```

## Data Sources

We plan on using data sources..., ..., ..

# Variables
Precincts 2020
- VTDST20: Voting district ID
- GEOID20: Unique geographic ID
- G20PRETRU: Total vote for trump in 2020
- G20PREBID: Total votes for Biden in 2020

US Congressional districts
- DISTRICT: US Congressional District Number
- POPULATION: Total Population (2020 census)
- WHITE: total white population (2020 census)
- BLACK: total Black or African American population (2020 census)

Block Groups
- GEOID: code to uniquely identify tracts
- P4_001N: Total Population, 18 years or older
- P4_006N: Total: Not Hispanic or Latino, Population of one race, Black or African American alone, 18 years or older
- P5_003N:Total institutionalized population in correctional facilities for adults, 18 years or older

## precints 2020

write code to read in precincts20.md into this document
```{r}
# here("Users","gushoward","Downloads","OR-gerrtmandere-Alabama","data","raw","public","alabama")

districts <- read_sf(here("data","raw","public","alabama","districts.gpkg"))

setwd()

censusblocks <- read_sf("block_groups.gpkg")
```


## Census
```{r}
census_metadata_file <- here("data", "metadata", "census2020pl_vars.csv")
if(file.exists(census_metadata_file)){
  census2020pl_vars <- read.csv(census_metadata_file)
} else {
  census2020pl_vars <- load_variables(2020, "pl")
  write.csv(census2020pl_vars, here("data", "metadata", "census2020pl_vars.csv"))
}
```

### block group
```{r message=FALSE, warning=FALSE}
blockgroup_file <- here("data", "raw", "public", "block_groups.gpkg")

# if the data is already downloaded, just load it
# otherwise, query from the census and save
if(file.exists(blockgroup_file)){
  blockgroups <- st_read(blockgroup_file)
} else {
  blockgroups <- get_decennial(geography = "block group",
                               sumfile = "pl",
                               table = "P3",
                               year = 2020,
                               state = "Alabama",
                               output = "wide",
                               geometry = TRUE,
                               keep_geo_vars = TRUE)
  st_write(blockgroups, blockgroup_file)
}
```

### census variables
```{r}
black_vars <- census2020pl_vars |> 
  dplyr::filter(str_detect(name, "P3"),
                str_detect(label, "Black")) |> 
  select(-concept)

black_vars |> kable()
```


```{r, message=FALSE, warning=FALSE}
blockgroups_calc <- blockgroups |> 
  rowwise() |> 
  mutate(Black = sum(c_across(all_of(black_vars$name)))) |> 
  ungroup() |> 
  mutate(Total = P3_001N,
         PctBlack = Black / Total * 100,
         CheckPct = (Black + P3_003N) / Total * 100) |> 
  # select(GEOID, Black, Total, PctBlack, CheckPct) |> 
  # mutate(bgarea = st_area(geom))
  select(GEOID, Black, Total, PctBlack, CheckPct)
```



```{r eval=FALSE}
st_write(blockgroups_calc, 
         here("data", "derived", "public", "blockgroups_calc.gpkg"),
         append=FALSE)
```

Map the percentage of the population 18 or over that is Black or African American.
```{r}
blkgrp_black <- blockgroups_calc |> 
  tm_shape() + 
tm_shape(blockgroups_calc) + 
  tm_polygons(
    fill = "PctBlack",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )

blkgrp_black
```

## Districts
```{r error=FALSE}
districts_file <- here("data", "raw", "public", "districts.gpkg")
st_layers(districts_file)
```

```{r}
districts21 <- st_read(districts_file, layer = "districts21")
```


```{r}
districts21 <- districts21 |> st_transform(4269) |> 
  mutate(pctBlack = round(BLACK / POPULATION * 100, 1))
```

Districts & black population

```{r}
tmap_mode(mode = "view")
blkgrp_black +
  tm_shape(districts21_results) +
  tm_polygons(col = "red",
              fill_alpha = 0,
              lwd = 2) +
  tm_text("DISTRICT",
          col = "red")
```

populations and bgs
```{r warning=FALSE}
districts21_estimates <- st_intersection(blockgroups_calc, districts21) |> 
  mutate(
    awTot = Total * as.numeric(st_area(geom) / bgarea),
    awBlack = Black * as.numeric(st_area(geom) / bgarea)
  ) |> 
  st_drop_geometry() |> 
  group_by(DISTRICT) |> 
  summarize(bgTotal = sum(awTot),
            bgBlack = sum(awBlack))

districts21_join_bg <- districts21 |> 
  left_join(districts21_estimates, by = "DISTRICT") |> 
  mutate(pctBlackbg = round(bgBlack / bgTotal * 100, 1))
```

```{r}
districts21_join_bg |> st_drop_geometry() |> kable()
```

blck pct
```{r warning=FALSE}
districts21_estimates <- st_intersection(blockgroups_calc, st_convex_hull(districts21)) |> 
  mutate(
    awTot = Total * as.numeric(st_area(geom) / bgarea),
    awBlack = Black * as.numeric(st_area(geom) / bgarea)
  ) |> 
  st_drop_geometry() |> 
  group_by(DISTRICT) |> 
  summarize(chTotal = sum(awTot),
            chBlack = sum(awBlack))
```

```{r}
districts21_join_ch <- districts21_join_bg |> 
  left_join(districts21_estimates, by = "DISTRICT") |> 
  mutate(pctBlackch = round(chBlack / chTotal * 100, 1),
         diffPct = pctBlackbg - pctBlackch,
         absdiffPct = abs(diffPct))
```

Calculate compactness scores.
To knit, will we need to replace `st_perimeter()` with `st_length(st_cast(st_cast(geom, "POLYGON"), "LINESTRING")`?

```{r}
districts21_results <- districts21_join_ch |> 
  mutate(
    darea = st_area(geom),
    compact_shp = round( as.numeric((4 * pi * darea) / st_perimeter(geom)^2), 2)
  )
```

Calculate compactness by comparing to the convex hull.

```{r}
districts21_results <- districts21_results |> 
  mutate(
    compact_hull = round( as.numeric(darea / st_area(st_convex_hull(geom))), 2)
  )
```

Calculate compactness by comparing to the minimum bounding circle.
This operation takes some time to run.

```{r}
districts21_results <- districts21_results |> 
  mutate(
    compact_circ = round( as.numeric(darea / st_area(st_minimum_bounding_circle(geom))), 2)
  )
```

### Plot representational difference against compactness


```{r}
districts21_results |> 
  st_drop_geometry() |> 
  select(absdiffPct, compact_shp, compact_hull, compact_circ) |> 
  cor() |> kable(digits = 2)
```


```{r}
tm_shape(districts21_results) +
  tm_polygons(fill = "pctBlackbg") +
  tm_text("DISTRICT")
```




## Prior observations  

At the time of this study pre-registration, the author had little prior knowledge of the geography of the study region with regards to the gerrymandering phenomena to be studied.
This study is related to one prior study by the author, in which the compactness of Alabama's voting districts was calculated, as well as voting statistics in relation to race.

## Bias and threats to validity

MAUP and Scale may affect these results.

Given the boundaries of this study are essential to the analysis, the Modifiable Areal Unit problem will certainly have relevant impacts. The constantly changing boundaries of voting precincts can impact both visualization of the data, as well as the analysis of it. The scale and shape of the units used has the potential to alter the data used in the study.

## Data transformations

```{r}

```


Describe all data transformations planned to prepare data sources for analysis.
This section should explain with the fullest detail possible how to transform data from the **raw** state at the time of acquisition or observation, to the pre-processed **derived** state ready for the main analysis.
Including steps to check and mitigate sources of **bias** and **threats to validity**.
The method may anticipate **contingencies**, e.g. tests for normality and alternative decisions to make based on the results of the test.
More specifically, all the **geographic** and **variable** transformations required to prepare input data as described in the data and variables section above to match the study's spatio-temporal characteristics as described in the study metadata and study design sections.
Visual workflow diagrams may help communicate the methodology in this section.

Examples of **geographic** transformations include coordinate system transformations, aggregation, disaggregation, spatial interpolation, distance calculations, zonal statistics, etc.

Examples of **variable** transformations include standardization, normalization, constructed variables, imputation, classification, etc.

Be sure to include any steps planned to **exclude** observations with *missing* or *outlier* data, to **group** observations by *attribute* or *geographic* criteria, or to **impute** missing data or apply spatial or temporal **interpolation**.

## Analysis

Describe the methods of analysis that will directly test the hypotheses or provide results to answer the research questions.
This section should explicitly define any spatial / statistical *models* and their *parameters*, including *grouping* criteria, *weighting* criteria, and *significance thresholds*.
Also explain any follow-up analyses or validations.

# Results

Describe how results are to be presented.

# Discussion

Describe how the results are to be interpreted *vis a vis* each hypothesis or research question.

# Integrity Statement

The authors of this preregistration state that they completed this preregistration to the best of their knowledge and that no other preregistration exists pertaining to the same hypotheses and research.
If a prior registration *does* exist, explain the rationale for revising the registration here.

# Acknowledgements


This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, DOI:[10.17605/OSF.IO/W29MQ](https://doi.org/10.17605/OSF.IO/W29MQ)

# References
